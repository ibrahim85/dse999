{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano example\n",
    "\n",
    "[Theano](http://deeplearning.net/software/theano/) is one of the many deep learning packages. It is written in Python and is designed to integrate well with NumPy. So it should feel pretty familar to us.\n",
    "\n",
    "It should be noted that-- as with most of these \"deep learning\" toolkits-- the library can be used to do all sorts of machine learning. It is *not* limited to simply neural networks. For example, you can implement [logistic regression](http://deeplearning.net/tutorial/logreg.html#logreg) or [KMeans](https://github.com/erogol/KLP_KMEANS). However, as you can see from the examples, these algorithms need to be hand coded. \n",
    "\n",
    "Theano/TensorFlow/Caffe/etc are really just symbolic math libraries. The advantage of using these libraries is that they are designed to be run on machines with GPUs. So--like Spark-- they allow us to run algorithms faster by distributing the calculations over several processors (in this case GPUs).\n",
    "\n",
    "We'll be using [Keras](https://keras.io/) as the actual interface to Theano/Tensorflow/etc. Keras provides an abstraction layer above Theano/TensorFlow. It will handle a lot of the heavy lifting so that we can just define the neural network parameters and it can handle the actual Theano/TensorFlow coding.\n",
    "\n",
    "I should also note that TensorFlow has officially supported [SKFlow](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn) which is a Sk-Learn binding to TensorFlow. This might be something that takes up traction as it gives you the pre-defined routines of sk-learn with the GPU scalability of TensorFlow. Examples of the typical sk-learn datasets are [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of Theano library\n",
    "import theano\n",
    "from theano import tensor  # This is not TensorFlow! It's just the tensor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "In the case of all of these packages, a tensor is just an abstraction for a N-dimensional matrix (N rank). So a scalar is a Tensor of dimension 0. A vector is a tensor of dimension 1, a matrix is a tensor of dimension 2. Tensors become useful for things like image processing because there are 3 color channels (red, green, blue). So a color image is $n \\times m \\times 3$ matrix or a 3-Tensor (n pixels width, m pixels height). A video would be a 4-Tensor $n \\times m \\times 3 \\times t$ where t is the index of the video frame. So tensors help us to store our data in a logical format and process them in a logical way (e.g. we know what a dimension refers to in the real world).\n",
    "\n",
    "Here's from the TensorFlow documentation:\n",
    "\n",
    " Tensor Rank |\tMathematical Construct |\tPython example \n",
    " :----: | -------     | ------\n",
    " 0    |\tScalar (magnitude only) |\ts = 123 \n",
    " 1 \t  | Vector (magnitude and direction) | \tv = [1.1, 2.2, 3.3] \n",
    " 2 \t  | Matrix (table of numbers) \t| m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \n",
    " 3 \t  | 3-Tensor (cube of numbers) |\tt = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare two symbolic floating-point scalars\n",
    "a = tensor.dscalar()\n",
    "b = tensor.dscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an expression\n",
    "\n",
    "So we are just defining that $c$ is the sum of $a$ and $b$. Theano (and TensorFlow) will understand that whenever you call $c$ you just need to evaluate this expression. The type for $c$ is automatically defined by the function and the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a simple symbolic expression\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the expression into a callable object that takes (a,b) and computes c\n",
    "f = theano.function([a,b], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the expression for some values\n",
    "\n",
    "Let's ask Theano to calculate the expression and report the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c'\n",
    "result = f(1.5, 2.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These things play well with NumPy. So we can pass any NumPy expression and it should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = theano.tensor.dmatrix('x')\n",
    "y = theano.tensor.dmatrix('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = theano.function([x, y], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  22.],\n",
       "       [ 33.,  44.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(np.array([[1, 2], [3, 4]]), np.array([[10, 20], [30, 40]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.      2.     10.    -32.891]\n"
     ]
    }
   ],
   "source": [
    "v = theano.tensor.vector() # declare variable\n",
    "out = v + np.power(v, 3)             \n",
    "h = theano.function([v], out)   # compile function\n",
    "print(h([0, 1, 2, -3.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
